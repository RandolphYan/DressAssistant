import os

from agentscope.message import Msg
from agentscope.msghub import msghub
import agentscope
from agentscope.agents.user_agent import UserAgent
# from agentscope.agents.dialog_agent import DialogAgent
from agentscope.agents.text_to_image_agent import TextToImageAgent
import gradio as gr
import requests
import concurrent.futures
from PIL import Image
import io


def get_weather():
    weather_key = '494d50b3bfe009cc5e0da51d25e6bff0'  # æ¯å¤©50æ¬¡è°ƒç”¨é¢åº¦, å°½é‡è‡ªå·±ç”³è¯·ä¸€ä¸ª https://dashboard.juhe.cn/data/index/my
    url = "http://apis.juhe.cn/simpleWeather/query"
    params = {
        'city': u'ä¸Šæµ·',
        'key': weather_key,
    }
    response = requests.get(url, params=params)
    data = response.json()
    if data['error_code'] != 0:
        print('å¤©æ°”å•ŠæŸ¥è¯¢å¤±è´¥ï¼ŒåŸå› ï¼š', data['reason'])
        return 'æœªæŸ¥è¯¢åˆ°å½“å‰å¤©æ°”'
    realtime_data = data['result']['realtime']
    realtime_str = 'å½“å‰å¤©æ°”%s, æ¸©åº¦ï¼š%sâ„ƒ, æ¹¿åº¦ï¼š%s%%, é£å‘ï¼š%s é£åŠ›ï¼š%s ç©ºæ°”è´¨é‡ï¼š%s' % (
        realtime_data['info'], realtime_data['temperature'], realtime_data['humidity'], realtime_data['direct'],
        realtime_data['power'], realtime_data['aqi']
    )

    return realtime_str


weather = get_weather()
API_KEY = os.getenv('DASHSCOPE_API_KEY')

agentscope.init(
    model_configs=[
        {
            "config_name": "neuralchat_config",  # é…ç½®åç§°ï¼Œéœ€è¦å”¯ä¸€
            "model_type": "openai_api",  # æ¨¡å‹ç±»å‹ï¼Œè¿™é‡Œä½¿ç”¨ post_api è¡¨ç¤º POST è¯·æ±‚çš„ API
            "api_url": "http://192.168.1.180:1611/v1/",  # ä½ çš„æœ¬åœ°æ¨¡å‹æœåŠ¡ URL
            "headers": {
                "Content-Type": "application/json",
                # API å¯†é’¥
                # "Authorization": "Bearer YOUR_API_KEY"
            },
            "json_args": {
                "model": "neural-chat-7b-v3-1",  # æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹
            },
            # å¦‚æœæœ‰å…¶ä»–éœ€è¦ä¼ é€’çš„å‚æ•°ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        },
        
        {
            "config_name": "tongyi_chat",
            "model_type": "dashscope_chat", "api_key": API_KEY,
            "model_name": "qwen-turbo"
        },
        {
            "config_name": "tongyi_image",
            "model_type": "dashscope_image_synthesis",
            "api_key": API_KEY,
            "model_name": "wanx-v1"
        }
    ]
)


consulter_prompt = '''
ä½ æ˜¯æˆ‘å¸çš„ç€è£…é¡¾é—®ï¼Œä½ çš„èŒè´£æ˜¯ä¸ºé¡¾å®¢æå‡ºé’ˆå¯¹æ€§çš„ç€è£…å»ºè®®
hostç»™å‡ºäº†é¡¾å®¢çš„è¦æ±‚ï¼Œä½ çš„å›å¤æ¨¡æ¿å¦‚ä¸‹ï¼š
---
[ç©¿æ­å»ºè®®]
    ä¸Šè¡£ï¼š{ç»™å‡ºä¸€ç§ä¸Šè¡£å»ºè®®}
    è£¤å­ï¼š{ç»™å‡ºä¸€ç§è£¤å­å»ºè®®}
    é‹å­ï¼š{ç»™å‡ºä¸€ç§é‹å­å»ºè®®}
    é…ä»¶ï¼š{ç»™å‡ºé…ä»¶å»ºè®®}
---
ä¸ºäº†é¿å…æ­§ä¹‰ï¼Œåº”å½“æ¯ä¸ªéƒ¨åˆ†æœ‰ä¸”ä»…æœ‰ä¸€ç§é£æ ¼çš„æ¨èï¼ˆå¦‚ä¸Šè¡£ï¼šä¸èƒ½åŒæ—¶æ¨èç™½è‰²Tæ¤å’Œå…¶ä»–é¢œè‰²çš„ä¸Šè¡£ï¼‰ã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šé¢çš„æ¨¡æ¿ç»™å‡ºä½ çš„å»ºè®®ã€‚å½“ä½ çš„å»ºè®®æ²¡æœ‰æŒ‰ç…§æ¨¡æ¿å›ç­”ï¼Œæˆ–æ˜¯å­˜åœ¨æ¨èä¸æ˜ç¡®çš„é—®é¢˜æ—¶ï¼ŒPMä¼šå›å¤noï¼Œå¹¶ç»™å‡ºç›¸åº”çš„è¯´æ˜ï¼Œä½ éœ€è¦æŒ‰ç…§ä»–ç»™å‡ºçš„æç¤ºä¿®æ”¹å»ºè®®
'''

painters_prompt = '''
ç»˜åˆ¶äººç‰©ç”»åƒ
'''

host_prompt = '''
æˆ‘ä»¬æ˜¯ä¸€å®¶ä¸ºé¡¾å®¢æä¾›ç©¿è¡£æ–¹æ¡ˆçš„å…¬å¸ï¼Œéœ€è¦æ ¹æ®éœ€æ±‚ä¸ºå®¢æˆ·æä¾›ä»Šæ—¥ç©¿æ­å»ºè®®ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›éœ€è¦çš„ä¿¡æ¯ï¼š
1. ä»Šå¤©æœ¬åœ°çš„å¤©æ°”ï¼š{}
2. ç”¨æˆ·å…·ä½“éœ€æ±‚ï¼š{}
{}
'''
# counselor = DialogAgent(
#     name="Consulter",
#     sys_prompt=consulter_prompt,
#     model_config_name="neuralchat_config",  # replace by your model config name
#     # model_config_name="tongyi_chat",  
# )

painter = TextToImageAgent(
    name="Painter",
    sys_prompt=consulter_prompt,
    model_config_name="tongyi_image",  # replace by your model config name
)

user = UserAgent(
    name="user",
)

def get_advice(prompt):
    import openai
    openai.api_key = "EMPTY"
    openai.base_url = 'http://192.168.1.180:1611/v1/'
    response = openai.chat.completions.create(
        model="neural-chat-7b-v3-1",
        # model="chatglm2",
        messages=[
            {"role": "system", "content": "you are a counselor, you need to provide dressing advice for the customer"},
            {"role": "user", "content": prompt},
        ]
    )
    return response.choices[0].message

def download_img_pil(index, img_url):
    # print(img_url)
    r = requests.get(img_url, stream=True)
    if r.status_code == 200:
        img = Image.open(io.BytesIO(r.content))
        return (index, img)
    else:
        gr.Error("å›¾ç‰‡ä¸‹è½½å¤±è´¥!")
        return

def download_images(img_urls,batch_size):
    imgs_pil = [None] * batch_size
    # ä¸‹è½½å•å¼ å›¾ç‰‡
    if batch_size == 1:
        with concurrent.futures.ThreadPoolExecutor(max_workers=batch_size) as executor:
            to_do = []
            future = executor.submit(download_img_pil, 1, img_urls)
            to_do.append(future)
            for future in concurrent.futures.as_completed(to_do):
                ret = future.result()
                # worker_results.append(ret)
                index, img_pil = ret
                imgs_pil[index-1] = img_pil 
        return img_pil
    
    else: # ä¸‹è½½å¤šå¼ å›¾ç‰‡æ”¾å…¥gallertä¸­
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            to_do = []
            for i, url in enumerate(img_urls):
                future = executor.submit(download_img_pil, i, url)
                to_do.append(future)

            for future in concurrent.futures.as_completed(to_do):
                ret = future.result()
                # worker_results.append(ret)
                index, img_pil = ret
                imgs_pil[index] = img_pil  # æŒ‰é¡ºåºæ’åˆ—urlï¼Œåç»­ä¸‹è½½å…³è”çš„å›¾ç‰‡æˆ–è€…svgéœ€è¦ä½¿ç”¨
        return imgs_pil

def dress_fn(user_requirement,actors):
    gr.Markdown("è¯·ç®€è¦æè¿°ä½ çš„ç‰¹å¾åŠåœºæ™¯ï¼š" + user_requirement)
    hint = Msg(
        name="Host",
        content=host_prompt.format(weather, user_requirement,consulter_prompt)  # user æè¿°ç¤ºä¾‹ 26å²ç”·æ€§ï¼Œä½“å‹åçŸ®å¾®èƒ–ï¼Œå¤§è…¿ç¨ç²—ï¼Œå‰è„šç•¥å®½ï¼›ä»Šå¤©å»æˆ·å¤–è¿åŠ¨
    )
    actors = [painter, user]
    with msghub(actors, announcement=hint):
        pass
    new_msg = Msg(name='', content="no")
    advices = []
    # for consulter in [consulter1, consulter2, consulter3]:
    msg = get_advice(hint.content)
    advice = msg.content     
    print("advice", advice)
    return advice

def generate_img(require,output):
    if len(require) == 0:
        raise gr.Error("äººç‰©ç‰¹å¾ä¸èƒ½ä¸ºç©º")
        return

    tempt_text = require + output
    new_msg = Msg(name='', content=tempt_text)
    img_res = painter(new_msg)
    img_data = download_images(img_res.url[0], len(img_res.url))
    return img_data


with gr.Blocks(css='style.css',theme=gr.themes.Soft()) as demo:
    with gr.Row():
        with gr.Column(scale=1):
            require = gr.Textbox(label="è¯·ç®€è¦æè¿°ä½ çš„ç‰¹å¾åŠåœºæ™¯ï¼š", value="30å²ç”·æ€§ï¼Œ170cmï¼Œä½“é‡60kgï¼Œä»Šå¤©å»æˆ·å¤–è¿åŠ¨")
            greet_btn = gr.Button("ç”Ÿæˆç©¿æ­å»ºè®®")
        # with gr.Column(scale=3):
            output = gr.Textbox(label="ç©¿æ­å»ºè®®")
        with gr.Column():
            # result = gr.HTML(label='preview', show_label=True, elem_classes='preview_html')
            # result_image = gr.Gallery(
            #    label='preview', show_label=True, elem_classes="preview_imgs", preview=True, interactive=False)
            output_image = gr.Image()
            btn = gr.Button(value="ç”Ÿæˆç©¿æ­ç”»åƒ", elem_classes='btn_gen')
            gr.Markdown("â™¨ï¸ å›¾ç‰‡è¾ƒå¤§ï¼ŒåŠ è½½è€—æ—¶ï¼Œç¨åŠ ç­‰å¾…~")
            # gr.Markdown("ğŸ“Œ é¼ æ ‡å³é”®ä¿å­˜åˆ°æœ¬åœ°ï¼Œæˆ–è€…åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€å¤§å›¾~")
    greet_btn.click(fn=dress_fn, inputs=require, outputs=output, api_name="dress_fn")
    btn.click(generate_img, inputs=[require,output],outputs=output_image)
    # new_msg = Msg(name='', content=output.value)
    # img_res = painter1(new_msg)
    # print("image", img_res)
    # gr.Image(value=img_res.url[0])

if __name__ == "__main__":
    demo.launch(share=True)

